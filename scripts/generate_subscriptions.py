#!/usr/bin/env python3
"""
è‡ªåŠ¨è®¢é˜…ç”Ÿæˆè„šæœ¬
ä»è¾“å…¥æºæ–‡ä»¶å¤¹è¯»å–.txtæ–‡ä»¶ä¸­çš„é“¾æ¥ï¼Œåˆå¹¶èŠ‚ç‚¹å¹¶ç”ŸæˆClashå…¼å®¹çš„YAMLæ–‡ä»¶
"""

import os
import re
import base64
import json
import requests
import yaml
from datetime import datetime
from urllib.parse import urlparse, urlencode, parse_qs
import time

def decode_base64(data):
    """è§£ç Base64æ•°æ®ï¼Œè‡ªåŠ¨è¡¥å…¨"""
    if not data:
        return None
    data = str(data).strip()
    missing_padding = len(data) % 4
    if missing_padding:
        data += '=' * (4 - missing_padding)
    try:
        return base64.urlsafe_b64decode(data).decode('utf-8', errors='ignore')
    except:
        try:
            return base64.b64decode(data).decode('utf-8', errors='ignore')
        except:
            return None

def parse_ss(ss_url):
    """è§£æSSé“¾æ¥"""
    try:
        # ç§»é™¤ ss:// å‰ç¼€
        url = ss_url[5:]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰@ç¬¦å·
        if '@' in url:
            # æ ¼å¼: method:password@server:port
            parts = url.split('@')
            method_password = parts[0]
            server_port = parts[1]
            
            # è§£ç method:passwordéƒ¨åˆ†
            if ':' in method_password:
                # å·²ç»æ˜¯æ˜æ–‡çš„method:password
                method, password = method_password.split(':', 1)
            else:
                # Base64ç¼–ç çš„
                decoded = decode_base64(method_password)
                if decoded and ':' in decoded:
                    method, password = decoded.split(':', 1)
                else:
                    return None
            
            server, port = server_port.split(':', 1)
            port = int(port)
            
            return {
                'name': f"SS-{server}:{port}",
                'type': 'ss',
                'server': server,
                'port': port,
                'cipher': method,
                'password': password,
                'udp': True
            }
        else:
            # å®Œæ•´Base64ç¼–ç æ ¼å¼
            decoded = decode_base64(url)
            if decoded:
                # æ ¼å¼: method:password@server:port
                if '@' in decoded:
                    parts = decoded.split('@')
                    method_password, server_port = parts[0], parts[1]
                    if ':' in method_password and ':' in server_port:
                        method, password = method_password.split(':', 1)
                        server, port = server_port.split(':', 1)
                        return {
                            'name': f"SS-{server}:{port}",
                            'type': 'ss',
                            'server': server,
                            'port': int(port),
                            'cipher': method,
                            'password': password,
                            'udp': True
                        }
    except Exception as e:
        print(f"è§£æSSé“¾æ¥å¤±è´¥ {ss_url[:50]}: {e}")
    return None

def parse_vmess(vmess_url):
    """è§£æVMessé“¾æ¥"""
    try:
        # ç§»é™¤ vmess:// å‰ç¼€å¹¶è§£ç 
        encoded = vmess_url[8:]
        decoded = decode_base64(encoded)
        if not decoded:
            return None
            
        # è§£æJSONé…ç½®
        config = json.loads(decoded)
        
        # åˆ›å»ºåŸºç¡€é…ç½®
        proxy_config = {
            'name': f"VMess-{config.get('ps', config.get('add', 'unknown'))}",
            'type': 'vmess',
            'server': config.get('add', ''),
            'port': int(config.get('port', 0)),
            'uuid': config.get('id', ''),
            'alterId': int(config.get('aid', 0)),
            'cipher': config.get('scy', 'auto'),
            'udp': True,
            'tls': config.get('tls') == 'tls',
            'skip-cert-verify': False
        }
        
        # æ·»åŠ servername
        sni = config.get('sni', config.get('host', ''))
        if sni:
            proxy_config['servername'] = sni
        
        # ç½‘ç»œç±»å‹è®¾ç½®
        network = config.get('net', 'tcp')
        if network == 'ws':
            proxy_config['network'] = 'ws'
            ws_opts = {
                'path': config.get('path', '/')
            }
            host = config.get('host', '')
            if host:
                ws_opts['headers'] = {'Host': host}
            proxy_config['ws-opts'] = ws_opts
        elif network == 'h2':
            proxy_config['network'] = 'h2'
            proxy_config['h2-opts'] = {
                'host': [config.get('host', '')],
                'path': config.get('path', '/')
            }
        elif network == 'grpc':
            proxy_config['network'] = 'grpc'
            proxy_config['grpc-opts'] = {
                'grpc-service-name': config.get('path', '')
            }
        
        return proxy_config
    except Exception as e:
        print(f"è§£æVMessé“¾æ¥å¤±è´¥ {vmess_url[:50]}: {e}")
    return None

def parse_trojan(trojan_url):
    """è§£æTrojané“¾æ¥"""
    try:
        # ç§»é™¤ trojan:// å‰ç¼€
        url = trojan_url[9:]
        
        # è§£æURL
        if '#' in url:
            url_part, fragment = url.split('#', 1)
        else:
            url_part, fragment = url, ''
            
        if '@' in url_part:
            # æ ¼å¼: password@server:port
            password_part, server_port = url_part.split('@', 1)
            password = password_part
            server, port = server_port.split(':', 1)
            
            # è§£ææŸ¥è¯¢å‚æ•°
            query_params = {}
            if '?' in port:
                port_part, query = port.split('?', 1)
                port = port_part
                query_params = parse_qs(query)
            
            config = {
                'name': f"Trojan-{server}:{port}",
                'type': 'trojan',
                'server': server,
                'port': int(port),
                'password': password,
                'udp': True,
                'sni': query_params.get('sni', [''])[0] or server,
                'skip-cert-verify': False
            }
            
            # æ·»åŠ fragmentä½œä¸ºname
            if fragment:
                config['name'] = fragment
            
            return config
    except Exception as e:
        print(f"è§£æTrojané“¾æ¥å¤±è´¥ {trojan_url[:50]}: {e}")
    return None

def parse_vless(vless_url):
    """è§£æVLESSé“¾æ¥"""
    try:
        # ç§»é™¤ vless:// å‰ç¼€
        url = vless_url[8:]
        
        # è§£æURL
        parsed = urlparse(f'vless://{url}')
        
        config = {
            'name': f"VLESS-{parsed.hostname}:{parsed.port}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': parsed.port,
            'uuid': parsed.username,
            'udp': True,
            'tls': True,
            'skip-cert-verify': False,
            'servername': parsed.hostname
        }
        
        # è§£ææŸ¥è¯¢å‚æ•°
        if parsed.query:
            params = parse_qs(parsed.query)
            if 'type' in params:
                config['network'] = params['type'][0]
            if 'security' in params:
                config['tls'] = params['security'][0] == 'tls'
            if 'path' in params and config.get('network') == 'ws':
                config['ws-opts'] = {
                    'path': params['path'][0]
                }
            if 'host' in params and config.get('network') == 'ws':
                if 'ws-opts' not in config:
                    config['ws-opts'] = {}
                config['ws-opts']['headers'] = {
                    'Host': params['host'][0]
                }
        
        # æ·»åŠ fragmentä½œä¸ºname
        if parsed.fragment:
            config['name'] = parsed.fragment
            
        return config
    except Exception as e:
        print(f"è§£æVLESSé“¾æ¥å¤±è´¥ {vless_url[:50]}: {e}")
    return None

def parse_proxy(proxy_str):
    """è§£æå•ä¸ªä»£ç†é“¾æ¥"""
    if not isinstance(proxy_str, str) or not proxy_str:
        return None
    
    proxy_str = proxy_str.strip()
    
    if proxy_str.startswith('ss://'):
        return parse_ss(proxy_str)
    elif proxy_str.startswith('vmess://'):
        return parse_vmess(proxy_str)
    elif proxy_str.startswith('trojan://'):
        return parse_trojan(proxy_str)
    elif proxy_str.startswith('vless://'):
        return parse_vless(proxy_str)
    elif proxy_str.startswith('ssr://'):
        # SSRé“¾æ¥ï¼Œæš‚æ—¶è·³è¿‡
        print(f"è·³è¿‡SSRé“¾æ¥: {proxy_str[:50]}...")
        return None
    elif len(proxy_str) > 10 and re.match(r'^[A-Za-z0-9+/=]+$', proxy_str):
        # å¯èƒ½æ˜¯Base64ç¼–ç çš„å®Œæ•´è®¢é˜…
        decoded = decode_base64(proxy_str)
        if decoded:
            # å°è¯•æŒ‰è¡Œè§£æ
            lines = decoded.split('\n')
            proxies = []
            for line in lines:
                line = line.strip()
                if line and not line.startswith('#') and '://' in line:
                    proxy = parse_proxy(line)
                    if proxy:
                        proxies.append(proxy)
            return proxies if proxies else None
    return None

def read_links_from_file(file_path):
    """ä»æ–‡æœ¬æ–‡ä»¶è¯»å–é“¾æ¥"""
    links = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    links.append(line)
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    return links

def fetch_subscription_content(url):
    """è·å–è®¢é˜…å†…å®¹"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/plain, */*; q=0.01'
    }
    
    try:
        print(f"æ­£åœ¨è·å–: {url}")
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        content = response.text.strip()
        print(f"  è·å–æˆåŠŸï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
        
        # å¦‚æœæ˜¯Base64ç¼–ç ï¼Œå°è¯•è§£ç 
        if content and len(content) > 10:
            # æ£€æŸ¥æ˜¯å¦æ˜¯Base64ï¼ˆåªåŒ…å«Base64å­—ç¬¦ä¸”é•¿åº¦åˆé€‚ï¼‰
            if re.match(r'^[A-Za-z0-9+/=\s]+$', content.replace('\n', '').replace('\r', '')):
                decoded = decode_base64(content)
                if decoded and any(keyword in decoded.lower() for keyword in ['ss://', 'vmess://', 'trojan://', 'vless://', 'proxies:', 'server:']):
                    print(f"  Base64è§£ç æˆåŠŸ")
                    return decoded
        
        return content
    except Exception as e:
        print(f"è·å–è®¢é˜…å¤±è´¥ {url}: {e}")
        return None

def parse_proxies_from_content(content):
    """ä»å†…å®¹ä¸­è§£æèŠ‚ç‚¹"""
    if not content:
        return []
    
    proxies = []
    
    # å…ˆå°è¯•è§£æä¸ºClash YAMLæ ¼å¼
    if 'proxies:' in content or 'Proxy:' in content.lower():
        try:
            # å°è¯•è§£æä¸ºYAML
            data = yaml.safe_load(content)
            if data and 'proxies' in data:
                print(f"  æ£€æµ‹åˆ°Clash YAMLæ ¼å¼ï¼Œæ‰¾åˆ° {len(data['proxies'])} ä¸ªèŠ‚ç‚¹")
                return data['proxies'][:100]  # é™åˆ¶æ•°é‡
        except:
            pass
    
    # æŒ‰è¡Œè§£æ
    lines = content.split('\n')
    print(f"  å¼€å§‹è§£æ {len(lines)} è¡Œå†…å®¹")
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        
        # å°è¯•è§£æå„ç§æ ¼å¼
        try:
            proxy = parse_proxy(line)
            if proxy:
                if isinstance(proxy, list):
                    proxies.extend(proxy)
                else:
                    proxies.append(proxy)
        except Exception as e:
            # å¿½ç•¥è§£æé”™è¯¯ï¼Œç»§ç»­ä¸‹ä¸€è¡Œ
            pass
    
    print(f"  è§£æå®Œæˆï¼Œæ‰¾åˆ° {len(proxies)} ä¸ªèŠ‚ç‚¹")
    return proxies

def generate_clash_config(proxies, filename):
    """ç”ŸæˆClashå…¼å®¹çš„YAMLé…ç½®"""
    if not proxies:
        print("  æ²¡æœ‰æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè·³è¿‡ç”Ÿæˆ")
        return 0
    
    # è¿‡æ»¤æ‰Noneå€¼
    proxies = [p for p in proxies if p]
    
    # åŸºç¡€é…ç½®
    config = {
        'port': 7890,
        'socks-port': 7891,
        'mixed-port': 7893,
        'allow-lan': True,
        'mode': 'Rule',
        'log-level': 'info',
        'external-controller': '0.0.0.0:9090',
        'secret': '',
        'dns': {
            'enable': True,
            'listen': '0.0.0.0:53',
            'default-nameserver': ['223.5.5.5', '8.8.8.8'],
            'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16',
            'nameserver': [
                'https://doh.pub/dns-query',
                'https://dns.alidns.com/dns-query'
            ]
        },
        'proxies': proxies[:100],  # é™åˆ¶æœ€å¤š100ä¸ªèŠ‚ç‚¹
        'proxy-groups': [
            {
                'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©',
                'type': 'select',
                'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ¯ å…¨çƒç›´è¿', 'DIRECT'] + [p.get('name', f'èŠ‚ç‚¹{i}') for i, p in enumerate(proxies[:10])]
            },
            {
                'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©',
                'type': 'url-test',
                'url': 'http://www.gstatic.com/generate_204',
                'interval': 300,
                'tolerance': 50,
                'proxies': [p.get('name', f'èŠ‚ç‚¹{i}') for i, p in enumerate(proxies[:50])]
            },
            {
                'name': 'ğŸ¯ å…¨çƒç›´è¿',
                'type': 'select',
                'proxies': ['DIRECT']
            }
        ],
        'rules': [
            'DOMAIN-SUFFIX,google.com,ğŸš€ èŠ‚ç‚¹é€‰æ‹©',
            'DOMAIN-SUFFIX,github.com,ğŸš€ èŠ‚ç‚¹é€‰æ‹©',
            'DOMAIN-SUFFIX,youtube.com,ğŸš€ èŠ‚ç‚¹é€‰æ‹©',
            'GEOIP,CN,ğŸ¯ å…¨çƒç›´è¿',
            'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©'
        ]
    }
    
    # å†™å…¥YAMLæ–‡ä»¶
    output_path = os.path.join('è®¢é˜…é“¾æ¥', f'{filename}.yaml')
    with open(output_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
    
    print(f"å·²ç”Ÿæˆæ–‡ä»¶: {output_path}ï¼ŒåŒ…å« {len(proxies[:100])} ä¸ªèŠ‚ç‚¹")
    return len(proxies[:100])

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ç”Ÿæˆè®¢é˜…...")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs('è®¢é˜…é“¾æ¥', exist_ok=True)
    
    # æ¸…ç†æ—§çš„è®¢é˜…æ–‡ä»¶
    import glob
    old_files = glob.glob('è®¢é˜…é“¾æ¥/*.yaml')
    for f in old_files:
        try:
            os.remove(f)
        except:
            pass
    
    # éå†è¾“å…¥æºæ–‡ä»¶å¤¹
    input_dir = 'è¾“å…¥æº'
    if not os.path.exists(input_dir):
        print(f"è¾“å…¥æºæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_dir}")
        # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
        os.makedirs(input_dir, exist_ok=True)
        with open(os.path.join(input_dir, 'example.txt'), 'w', encoding='utf-8') as f:
            f.write("# åœ¨æ­¤æ·»åŠ è®¢é˜…é“¾æ¥ï¼Œæ¯è¡Œä¸€ä¸ª\n")
            f.write("# ä¾‹å¦‚ï¼š\n")
            f.write("# https://example.com/subscribe.txt\n")
        print("å·²åˆ›å»ºç¤ºä¾‹æ–‡ä»¶: è¾“å…¥æº/example.txt")
        return
    
    for filename in os.listdir(input_dir):
        if filename.endswith('.txt'):
            file_path = os.path.join(input_dir, filename)
            print(f"\nå¤„ç†æ–‡ä»¶: {filename}")
            
            # è¯»å–é“¾æ¥
            links = read_links_from_file(file_path)
            if not links:
                print(f"  æœªæ‰¾åˆ°é“¾æ¥: {filename}")
                continue
            
            all_proxies = []
            
            # è·å–æ¯ä¸ªé“¾æ¥çš„å†…å®¹
            for i, link in enumerate(links):
                print(f"\n  è·å–é“¾æ¥ [{i+1}/{len(links)}]: {link[:60]}...")
                content = fetch_subscription_content(link)
                if content:
                    proxies = parse_proxies_from_content(content)
                    if proxies:
                        all_proxies.extend(proxies)
                        print(f"    æ‰¾åˆ° {len(proxies)} ä¸ªèŠ‚ç‚¹")
                    else:
                        print(f"    æœªæ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
                    
                    # é¿å…è¯·æ±‚è¿‡å¿«
                    if i < len(links) - 1:
                        time.sleep(2)
                else:
                    print(f"    è·å–å†…å®¹å¤±è´¥")
            
            # å»é‡ï¼ˆåŸºäºæœåŠ¡å™¨å’Œç«¯å£ï¼‰
            unique_proxies = []
            seen = set()
            for proxy in all_proxies:
                if proxy and isinstance(proxy, dict):
                    server = proxy.get('server', '')
                    port = proxy.get('port', 0)
                    if server and port:
                        key = f"{server}:{port}:{proxy.get('type', '')}"
                        if key not in seen:
                            seen.add(key)
                            unique_proxies.append(proxy)
            
            print(f"\n  å»é‡å: {len(unique_proxies)} ä¸ªå”¯ä¸€èŠ‚ç‚¹")
            
            # ç”ŸæˆYAMLæ–‡ä»¶
            if unique_proxies:
                base_name = os.path.splitext(filename)[0]
                count = generate_clash_config(unique_proxies, base_name)
                print(f"  ç”Ÿæˆæ–‡ä»¶å®Œæˆï¼ŒåŒ…å« {count} ä¸ªèŠ‚ç‚¹")
            else:
                print(f"  æœªæ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè·³è¿‡ç”Ÿæˆ")
                # ç”Ÿæˆä¸€ä¸ªç©ºçš„é…ç½®æ–‡ä»¶ä»¥é¿å…é”™è¯¯
                config = {
                    'proxies': [],
                    'proxy-groups': [{
                        'name': 'æ— å¯ç”¨èŠ‚ç‚¹',
                        'type': 'select',
                        'proxies': ['DIRECT']
                    }],
                    'rules': ['MATCH,æ— å¯ç”¨èŠ‚ç‚¹']
                }
                base_name = os.path.splitext(filename)[0]
                output_path = os.path.join('è®¢é˜…é“¾æ¥', f'{base_name}.yaml')
                with open(output_path, 'w', encoding='utf-8') as f:
                    yaml.dump(config, f, allow_unicode=True)
                print(f"  å·²ç”Ÿæˆç©ºé…ç½®æ–‡ä»¶: {output_path}")
    
    print("\nè®¢é˜…ç”Ÿæˆå®Œæˆï¼")

if __name__ == '__main__':
    main()
