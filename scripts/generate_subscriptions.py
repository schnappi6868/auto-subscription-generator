#!/usr/bin/env python3
"""
è‡ªåŠ¨è®¢é˜…ç”Ÿæˆè„šæœ¬
ä»è¾“å…¥æºæ–‡ä»¶å¤¹è¯»å–.txtæ–‡ä»¶ä¸­çš„é“¾æ¥ï¼Œåˆå¹¶èŠ‚ç‚¹å¹¶ç”ŸæˆACL4SSRæ ¼å¼çš„YAMLæ–‡ä»¶
"""

import os
import re
import requests
import yaml
from datetime import datetime
from urllib.parse import urlparse
import time

def read_links_from_file(file_path):
    """ä»æ–‡æœ¬æ–‡ä»¶è¯»å–é“¾æ¥"""
    links = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):  # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                    links.append(line)
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    return links

def fetch_subscription_content(url):
    """è·å–è®¢é˜…å†…å®¹"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        return response.text
    except Exception as e:
        print(f"è·å–è®¢é˜…å¤±è´¥ {url}: {e}")
        return None

def parse_proxies_from_content(content):
    """ä»å†…å®¹ä¸­è§£æèŠ‚ç‚¹"""
    proxies = []
    
    # è§£æå„ç§æ ¼å¼çš„èŠ‚ç‚¹
    lines = content.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # SS/SSRæ ¼å¼
        if line.startswith('ss://') or line.startswith('ssr://'):
            proxies.append(line)
        # VMessæ ¼å¼
        elif line.startswith('vmess://'):
            proxies.append(line)
        # Trojanæ ¼å¼
        elif line.startswith('trojan://'):
            proxies.append(line)
        # VLESSæ ¼å¼
        elif line.startswith('vless://'):
            proxies.append(line)
        # Base64ç¼–ç çš„èŠ‚ç‚¹
        elif re.match(r'^[A-Za-z0-9+/=]+$', line):
            proxies.append(line)
    
    return proxies

def generate_acl4ssr_yaml(proxies, filename):
    """ç”ŸæˆACL4SSRæ ¼å¼çš„YAMLæ–‡ä»¶"""
    config = {
        'port': 7890,
        'socks-port': 7891,
        'allow-lan': True,
        'mode': 'Rule',
        'log-level': 'info',
        'external-controller': '0.0.0.0:9090',
        'dns': {
            'enable': True,
            'listen': '0.0.0.0:53',
            'default-nameserver': ['223.5.5.5', '8.8.8.8'],
            'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16',
            'nameserver': [
                'https://doh.pub/dns-query',
                'https://dns.alidns.com/dns-query'
            ]
        },
        'proxies': [],
        'proxy-groups': [
            {
                'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©',
                'type': 'select',
                'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ¯ å…¨çƒç›´è¿']
            },
            {
                'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©',
                'type': 'url-test',
                'url': 'http://www.gstatic.com/generate_204',
                'interval': 300,
                'tolerance': 50,
                'proxies': []
            },
            {
                'name': 'ğŸ“º å“”å“©å“”å“©',
                'type': 'select',
                'proxies': ['ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ¯ å…¨çƒç›´è¿']
            },
            {
                'name': 'ğŸŒ å›½å¤–åª’ä½“',
                'type': 'select',
                'proxies': ['ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ¯ å…¨çƒç›´è¿']
            },
            {
                'name': 'â“‚ï¸ å¾®è½¯æœåŠ¡',
                'type': 'select',
                'proxies': ['ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'ğŸ¯ å…¨çƒç›´ç›´è¿']
            },
            {
                'name': 'ğŸ è‹¹æœæœåŠ¡',
                'type': 'select',
                'proxies': ['ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'ğŸ¯ å…¨çƒç›´è¿']
            },
            {
                'name': 'ğŸ¯ å…¨çƒç›´è¿',
                'type': 'select',
                'proxies': ['DIRECT']
            },
            {
                'name': 'ğŸ›‘ å¹¿å‘Šæ‹¦æˆª',
                'type': 'select',
                'proxies': ['REJECT', 'DIRECT']
            }
        ],
        'rules': [
            'DOMAIN-SUFFIX,ads.com,REJECT',
            'DOMAIN-KEYWORD,adservice,REJECT',
            'DOMAIN-SUFFIX,bilibili.com,ğŸ“º å“”å“©å“”å“©',
            'DOMAIN-SUFFIX,bilibili.tv,ğŸ“º å“”å“©å“”å“©',
            'DOMAIN-SUFFIX,netflix.com,ğŸŒ å›½å¤–åª’ä½“',
            'DOMAIN-SUFFIX,disneyplus.com,ğŸŒ å›½å¤–åª’ä½“',
            'DOMAIN-SUFFIX,microsoft.com,â“‚ï¸ å¾®è½¯æœåŠ¡',
            'DOMAIN-SUFFIX,apple.com,ğŸ è‹¹æœæœåŠ¡',
            'GEOIP,CN,ğŸ¯ å…¨çƒç›´è¿',
            'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©'
        ]
    }
    
    # æ·»åŠ ä»£ç†åˆ°é…ç½®
    for i, proxy in enumerate(proxies[:100]):  # é™åˆ¶æœ€å¤š100ä¸ªèŠ‚ç‚¹
        proxy_name = f"èŠ‚ç‚¹{i+1:03d}"
        
        # å°è¯•è§£æä»£ç†ç±»å‹
        if proxy.startswith('ss://'):
            config['proxies'].append({
                'name': proxy_name,
                'type': 'ss',
                'server': 'server.address',  # éœ€è¦å®é™…è§£æ
                'port': 443,
                'cipher': 'aes-256-gcm',
                'password': 'password'
            })
        elif proxy.startswith('vmess://'):
            config['proxies'].append({
                'name': proxy_name,
                'type': 'vmess',
                'server': 'server.address',
                'port': 443,
                'uuid': 'uuid',
                'alterId': 0,
                'cipher': 'auto',
                'tls': True
            })
        else:
            # æ·»åŠ ä¸ºåŸå§‹å­—ç¬¦ä¸²
            config['proxies'].append(proxy)
        
        # æ·»åŠ åˆ°è‡ªåŠ¨é€‰æ‹©ç»„
        config['proxy-groups'][1]['proxies'].append(proxy_name)
    
    # å†™å…¥YAMLæ–‡ä»¶
    output_path = os.path.join('è®¢é˜…é“¾æ¥', f'{filename}.yaml')
    with open(output_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
    
    print(f"å·²ç”Ÿæˆæ–‡ä»¶: {output_path}ï¼ŒåŒ…å« {len(proxies)} ä¸ªèŠ‚ç‚¹")
    return len(proxies)

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ç”Ÿæˆè®¢é˜…...")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs('è®¢é˜…é“¾æ¥', exist_ok=True)
    
    # éå†è¾“å…¥æºæ–‡ä»¶å¤¹
    input_dir = 'è¾“å…¥æº'
    if not os.path.exists(input_dir):
        print(f"è¾“å…¥æºæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_dir}")
        return
    
    for filename in os.listdir(input_dir):
        if filename.endswith('.txt'):
            file_path = os.path.join(input_dir, filename)
            print(f"å¤„ç†æ–‡ä»¶: {filename}")
            
            # è¯»å–é“¾æ¥
            links = read_links_from_file(file_path)
            if not links:
                print(f"  æœªæ‰¾åˆ°é“¾æ¥: {filename}")
                continue
            
            all_proxies = []
            
            # è·å–æ¯ä¸ªé“¾æ¥çš„å†…å®¹
            for link in links:
                print(f"  è·å–é“¾æ¥: {link}")
                content = fetch_subscription_content(link)
                if content:
                    proxies = parse_proxies_from_content(content)
                    all_proxies.extend(proxies)
                    print(f"    æ‰¾åˆ° {len(proxies)} ä¸ªèŠ‚ç‚¹")
                    time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            # å»é‡
            unique_proxies = list(dict.fromkeys(all_proxies))
            
            # ç”ŸæˆYAMLæ–‡ä»¶
            if unique_proxies:
                base_name = os.path.splitext(filename)[0]
                count = generate_acl4ssr_yaml(unique_proxies, base_name)
                print(f"  æ€»è®¡: {count} ä¸ªå”¯ä¸€èŠ‚ç‚¹")
            else:
                print(f"  æœªæ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
    
    print("è®¢é˜…ç”Ÿæˆå®Œæˆï¼")

if __name__ == '__main__':
    main()
